{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jstephencorey/bert-experiments/blob/main/bert_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z4gk4mBXNE5d"
      },
      "outputs": [],
      "source": [
        "on_colab = True\n",
        "first_run = False # Change this when you disconnect and reconnect the runtime\n",
        "if on_colab and first_run:\n",
        "    !git clone https://github.com/jstephencorey/bert-experiments.git  bert_git # Only need to run this on colab\n",
        "    from pathlib import Path\n",
        "    import sys\n",
        "    sys.path.append(str('/content/bert_git')) #Only need on the colab\n",
        "    print(sys.path)\n",
        "    !pip install transformers --quiet\n",
        "    !pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiNtU2K1NE5i",
        "outputId": "0d457553-fe26-439d-fd3e-fcd23e5027c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjstephencorey\u001b[0m (\u001b[33msintez\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import random\n",
        "from torch import optim\n",
        "import bert\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5Tt1jGO5P25I",
        "outputId": "5d287297-35b8-4e7c-b3f1-4424fa2b89ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the tokenizers"
      ],
      "metadata": {
        "id": "yVJD6juiPgQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "btlU5Is0Pr7N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/AI_Data/'\n",
        "MODEL_DIR = '/content/drive/MyDrive/AI_Models/storygpt/'\n",
        "TOKENIZER_DIR = f'{MODEL_DIR}storygpt2tokenizer_ft2/'\n",
        "\n",
        "bibliotik_train = f'{DATA_DIR}bibliotik_corpus/biblitik_22500_full.gz'\n",
        "bibliotik_val = f'{DATA_DIR}bibliotik_corpus/biblitik_7500_val.gz'\n",
        "\n",
        "atlas_shrugged_filename = f'{DATA_DIR}atlas-shrugged.txt'\n",
        "anthem_filename = f'{DATA_DIR}anthem.txt'"
      ],
      "metadata": {
        "id": "A0oATDFxPwsv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QkS_SvWjQV7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up the model"
      ],
      "metadata": {
        "id": "-RMatIDBPkbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U1Md96FKNE5k"
      },
      "outputs": [],
      "source": [
        "test_parts = True\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_name = \"bert_init_test_0\"\n",
        "\n",
        "wandb.init(project=\"bert_experiments\", \n",
        "           name=run_name,\n",
        "           )\n",
        "\n",
        "wandb.config = {\n",
        "  \"epochs\": 5,\n",
        "  \"batch_size\": None,\n",
        "  \"val_batch_size\": None,\n",
        "  \"seed\":135,\n",
        "  # Model info\n",
        "  \"context_len\": 256,\n",
        "  \"d_model\":768,\n",
        "  \"num_layers\":12,\n",
        "  \"n_head\":12,\n",
        "  \"lr\": 1e-4,\n",
        "  # \"stories_per_epoch\": 5000,\n",
        "  \"save_model\": True,\n",
        "  \"from_pretrained\": False,#f'{MODEL_DIR}gpt-3-test-8-0.pt'\n",
        "  \"val_seqs_per_story\": 32, #More is faster, but smaller is more generalizable\n",
        "  \"bert_model_name\": 'distilbert-base-cased',\n",
        "  \"bert_mask_percentage\": .2,\n",
        "}\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "random.seed(config['seed'])\n",
        "torch.random.manual_seed(config['seed'])\n",
        "\n",
        "print(config)"
      ],
      "metadata": {
        "id": "bwMqSlE8OSgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h4zywtNaNE5k"
      },
      "outputs": [],
      "source": [
        "model = bert.BertModel(d_model = 512, \n",
        "                        vocab_length = 30, \n",
        "                        sequence_length = config['context_len'],\n",
        "                        num_layers = 8, \n",
        "                        feed_forward_dimensions = 1024, \n",
        "                        attention_heads = 8,\n",
        "                        attention_qkv_dims =  128, \n",
        "                        dropout = 0.1, \n",
        "                        pad_idx = 3, \n",
        "                        device = \"CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5JHO_adNE5l",
        "outputId": "eaa86277-57a4-4897-8b4c-891d9a1e4dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 10, 30])\n"
          ]
        }
      ],
      "source": [
        "if test_parts:\n",
        "    inp = torch.LongTensor([[0,1,2,3,4,5,6,7,8,29],[1,3,4,5,6,8,0,22,1,1]])\n",
        "    out = model(inp)\n",
        "    print(out.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLzZemWbNE5l"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVXP07moNE5m",
        "outputId": "d7ef8b5e-3796-4131-9920-d819fea59445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "torch.Size([2, 10, 30]) torch.Size([2, 10])\n",
            "Epoch: 0010 cost = 53.527332\n"
          ]
        }
      ],
      "source": [
        "batch = torch.LongTensor([[0,1,2,3,4,5,6,7,8,29],[1,3,4,5,6,8,0,22,1,1]])\n",
        "print(batch.size())\n",
        "# input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(*batch))\n",
        "\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    optimizer.zero_grad()\n",
        "    logits_lm = model(batch)\n",
        "    print(logits_lm.size(), batch.size())\n",
        "    loss_lm = criterion(logits_lm.transpose(1, 2), batch) # for masked LM\n",
        "    loss_lm = (loss_lm.float()).mean()\n",
        "    # loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
        "    loss = loss_lm #+ loss_clsf\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# # Predict mask tokens\n",
        "# input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[0]))\n",
        "# print(text)\n",
        "# print([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])\n",
        "\n",
        "# logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
        "# logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n",
        "# print('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n",
        "# print('predict masked tokens list : ',[pos for pos in logits_lm if pos != 0])\n",
        "\n",
        "# logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
        "# print('isNext : ', True if isNext else False)\n",
        "# print('predict isNext : ',True if logits_clsf else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-23iqZnNE5n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e5cdae407986fbcf9f40eb4f2caf8136385e94546bed8444298080b1cba2358b"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}